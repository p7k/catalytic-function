{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import scipy as sp\n",
    "from sys import getsizeof\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Row-Col format. More intuitive. Was a bit slow.\n",
    "Think would work if i csr.eliminate_zeros() before\n",
    "calling sort and then do\n",
    "row, col = sparse_arr.nonzero()\n",
    "data = sparse_arr.data\n",
    "'''\n",
    "\n",
    "# def sort_sparse(sparse_arr, axis, descending=True):\n",
    "#     axis = axis ^ 1\n",
    "#     row, col = sparse_arr.nonzero()\n",
    "#     data = [sparse_arr[row[i], col[i]] for i in range(len(row))]\n",
    "#     sorted_nonzero = sorted(zip(row, col, data), key=lambda x: (x[axis], x[-1]), reverse=descending)\n",
    "\n",
    "#     axwise_sort = {}\n",
    "#     for elt in sorted_nonzero:\n",
    "#         if elt[0] not in axwise_sort:\n",
    "#             axwise_sort[elt[axis]] = [elt[-1]]\n",
    "#         else:\n",
    "#             axwise_sort[elt[axis]].append(elt[-1])\n",
    "\n",
    "#     return axwise_sort\n",
    "\n",
    "# def sort_sparse_idx(sparse_arr, axis, descending=True):\n",
    "#     other = axis\n",
    "#     axis = axis ^ 1\n",
    "#     row, col = sparse_arr.nonzero()\n",
    "#     print(\"Pulling data\")\n",
    "#     # data = [sparse_arr[row[i], col[i]] for i in range(len(row))]\n",
    "#     data = sparse_arr.data\n",
    "#     print(\"Sorting data\")\n",
    "#     foo = zip(row, col, data)\n",
    "#     sorted_nonzero = sorted(zip(row, col, data), key=lambda x: (x[axis], x[-1]), reverse=descending)\n",
    "\n",
    "#     print(\"Constructing dict\")\n",
    "#     axwise_sort = {}\n",
    "#     for elt in sorted_nonzero:\n",
    "#         if elt[0] not in axwise_sort:\n",
    "#             axwise_sort[elt[axis]] = [elt[other]]\n",
    "#         else:\n",
    "#             axwise_sort[elt[axis]].append(elt[other])\n",
    "\n",
    "#     return axwise_sort\n",
    "\n",
    "'''\n",
    "Canonical format\n",
    "'''\n",
    "\n",
    "def sort_sparse_axwise(sparse_arr, descending=True):\n",
    "    axwise_sorted_idxs = {}\n",
    "    for i in range(sparse_arr.indptr.shape[0] - 1):\n",
    "        idxs = sparse_arr.indices[sparse_arr.indptr[i]:sparse_arr.indptr[i+1]]\n",
    "\n",
    "        if idxs.shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        data = sparse_arr.data[sparse_arr.indptr[i]:sparse_arr.indptr[i+1]]\n",
    "        data_sorted_idxs = np.array(sorted(zip(data, idxs), reverse=descending)).astype(np.int32)\n",
    "        axwise_sorted_idxs[i] = data_sorted_idxs\n",
    "\n",
    "    return axwise_sorted_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = 'new'\n",
    "y_fn = \"protein_x_catalytic_function.npz\"\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(seed=1234)\n",
    "path = f\"../data/{dataset}/\"\n",
    "\n",
    "# Read data table of contents csv\n",
    "df = pd.read_csv(path + f\"{dataset}.csv\", delimiter='\\t')\n",
    "df.set_index('Entry', inplace=True)\n",
    "entry_idxs = list(df.index)\n",
    "ec_idxs = set()\n",
    "for elt in df.loc[:, \"EC number\"]:\n",
    "    for ec in elt.split(';'):\n",
    "        ec_idxs.add(ec)\n",
    "ec_idxs = list(ec_idxs)\n",
    "\n",
    "n_samples = len(entry_idxs)\n",
    "n_features = len(ec_idxs)\n",
    "\n",
    "if os.path.exists(path + y_fn):\n",
    "    print(\"Loading\")\n",
    "    y = sp.sparse.load_npz(path + y_fn)\n",
    "    row, col = y.nonzero()\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(row)):\n",
    "        data.append(y[row[i], col[i]])\n",
    "\n",
    "\n",
    "else:\n",
    "    # Construct ground truth protein-function matrix\n",
    "    print(\"Constructing y\")\n",
    "    row, col, data = [], [], [] # For csr\n",
    "    i = 0\n",
    "    for elt in df.index:\n",
    "        ecs = df.loc[elt, 'EC number'].split(';')\n",
    "        i = entry_idxs.index(elt)\n",
    "        for ec in ecs:\n",
    "            j = ec_idxs.index(ec)\n",
    "            row.append(i)\n",
    "            col.append(j)\n",
    "            data.append(1)\n",
    "        \n",
    "        i += 1\n",
    "        print(f\"{i}/{n_samples}\", end='\\r')\n",
    "\n",
    "    y = sp.sparse.csr_array((data, (row, col)))\n",
    "    print(\"\\nSaving y\")\n",
    "    sp.sparse.save_npz(path + y_fn, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get ones to mask\n",
      "Get zeros to mask\n",
      "n0:1\n",
      "Sorting similarity matrix\n"
     ]
    }
   ],
   "source": [
    "percent_to_mask = 0.01\n",
    "\n",
    "\n",
    "n_mask = int((len(row) * percent_to_mask) / 2) # 50-50 split of 1s and 0s of 1% of elements\n",
    "\n",
    "# Sample ones\n",
    "print(\"Get ones to mask\")\n",
    "rnd_idxs = rng.integers(0, len(row), size=(n_mask,))\n",
    "mask_row, mask_col, y_true = zip(*[(row[idx], col[idx], 1) for idx in rnd_idxs])\n",
    "mask_row, mask_col, y_true = list(mask_row), list(mask_col), list(y_true)\n",
    "\n",
    "# Mask ones\n",
    "for elt in range(len(mask_row)):\n",
    "    i, j = mask_row[elt], mask_col[elt]\n",
    "    y[i, j] = 0\n",
    "\n",
    "y.eliminate_zeros()\n",
    "\n",
    "# Sample zeros\n",
    "print(\"Get zeros to mask\")\n",
    "n0 = 0\n",
    "sampled_ones_idxs = list(zip(mask_row, mask_col))\n",
    "while n0 < n_mask:\n",
    "    print(f\"n0:{n0}\", end='\\r')\n",
    "    sampled_idx = (rng.integers(0, n_samples), rng.integers(0, n_features))\n",
    "\n",
    "    if sampled_idx not in sampled_ones_idxs:\n",
    "        mask_row.append(sampled_idx[0])\n",
    "        mask_col.append(sampled_idx[1])\n",
    "        y_true.append(0)\n",
    "        n0 += 1\n",
    "\n",
    "similarity = y @ y.T # Prot-prot similarity matrix\n",
    "similarity.eliminate_zeros()\n",
    "\n",
    "# Zero out all but k nearest neighbors\n",
    "print(\"\\nSorting similarity matrix\")\n",
    "rowwise_sorted_sparse = sort_sparse_axwise(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3 # K-nearest-neighbors\n",
    "indptr = [0]\n",
    "indices = np.array([])\n",
    "data = np.array([])\n",
    "for i in range(similarity.shape[0]):\n",
    "    v = rowwise_sorted_sparse.get(i, None)\n",
    "    if v is not None:\n",
    "        indices = np.hstack((indices, v[:k, 1]))\n",
    "        data = np.hstack((data, v[:k, 0]))\n",
    "\n",
    "        if k < v.shape[0]:\n",
    "            indptr.append(indptr[-1] + k)\n",
    "        else:\n",
    "            indptr.append(indptr[-1] + v.shape[0])\n",
    "    \n",
    "    else:\n",
    "        indptr.append(indptr[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Normalizing similarity matrix\n",
      "Accuracy: 0.5\n",
      "ROC AUC: 0.5\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_105675/3077746288.py:6: RuntimeWarning: divide by zero encountered in divide\n",
      "  similarity_k = similarity_k.multiply(1 / row_sum)\n"
     ]
    }
   ],
   "source": [
    "similarity_k = sp.sparse.csr_array((data, indices, indptr), shape=similarity.shape)\n",
    "print(similarity_k.shape == similarity.shape)\n",
    "\n",
    "print(\"Normalizing similarity matrix\")\n",
    "row_sum = similarity_k.sum(axis=1).reshape(-1,1)\n",
    "similarity_k = similarity_k.multiply(1 / row_sum)\n",
    "\n",
    "# Predict \n",
    "y_hat = similarity_k @ y\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_hat[mask_row, mask_col]).reshape(-1,)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred>0)\n",
    "roc_auc = roc_auc_score(y_true, y_pred>0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "\n",
    "\n",
    "print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12 s/ 20000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.perf_counter()\n",
    "n = 20000\n",
    "for i in range(n):\n",
    "    print(f\"{i} / {n}\", end='\\r')\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f\"{toc - tic:.2f} s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
