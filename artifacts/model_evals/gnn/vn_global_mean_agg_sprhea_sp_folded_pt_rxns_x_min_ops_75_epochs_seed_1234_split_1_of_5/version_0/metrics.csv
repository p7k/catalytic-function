epoch,step,train_loss
0,49,1625.547607421875
0,49,1601.137939453125
1,99,1060.8265380859375
1,99,1014.40673828125
1,149,1964.4578857421875
1,149,1775.565185546875
2,199,872.5518798828125
2,199,781.3389892578125
2,249,953.2142944335938
2,249,931.496826171875
3,299,965.454345703125
3,299,890.9398193359375
3,349,539.2926025390625
3,349,555.04345703125
4,399,549.079833984375
4,399,362.67266845703125
5,449,202.5009765625
5,449,169.6230010986328
5,499,112.95231628417969
5,499,131.85333251953125
6,549,304.11334228515625
6,549,279.3091125488281
6,599,102.92082214355469
6,599,87.68595886230469
7,649,76.66226959228516
7,649,93.68830871582031
7,699,154.93954467773438
7,699,122.29840850830078
8,749,46.76776885986328
8,749,65.5136947631836
8,799,96.28870391845703
8,799,107.8466567993164
9,849,73.00687408447266
9,849,60.48310089111328
10,899,25.96192169189453
10,899,32.573421478271484
10,949,30.98700714111328
10,949,49.75536346435547
11,999,14.799762725830078
11,999,13.605350494384766
11,1049,71.22989654541016
11,1049,46.15117645263672
12,1099,7.595841407775879
12,1099,14.614606857299805
12,1149,34.6605110168457
12,1149,45.88957977294922
13,1199,17.663467407226562
13,1199,15.2239990234375
14,1249,31.178138732910156
14,1249,45.0712776184082
14,1299,3.8822247982025146
14,1299,3.643193244934082
15,1349,22.00241470336914
15,1349,20.702848434448242
15,1399,6.981051445007324
15,1399,3.957847833633423
16,1449,37.39969253540039
16,1449,29.244766235351562
16,1499,14.847506523132324
16,1499,12.887861251831055
17,1549,9.245927810668945
17,1549,5.447995185852051
17,1599,14.283717155456543
17,1599,10.006990432739258
18,1649,6.779063701629639
18,1649,4.905133247375488
19,1699,4.363679885864258
19,1699,4.116288661956787
19,1749,3.4767391681671143
19,1749,1.8284859657287598
20,1799,1.9482522010803223
20,1799,1.3573384284973145
